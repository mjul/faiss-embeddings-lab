{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pathlib\n",
    "import urllib.request\n",
    "\n",
    "import faiss\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "MODEL_DIR = pathlib.Path().absolute().parent / \"models\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define the device to use, using a CUDA GPU if available.\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the pre-trained tokenizer and model\n",
    "model_name = ['bert-base-uncased',\n",
    "              'bert-large-uncased',\n",
    "              'facebook/bart-large-mnli'\n",
    "              ][1]\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir=MODEL_DIR)\n",
    "model = AutoModel.from_pretrained(model_name).to(device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Download the sonnets (free for non-commercial use)\n",
    "url = \"https://flgr.sh/txtfssSontxt\"\n",
    "document = [b.decode('UTF-8') for b in urllib.request.urlopen(url).readlines()]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "without_header = list(itertools.dropwhile(lambda x: len(x.strip()) > 0, document))\n",
    "cleaned = [str(line).strip() for line in without_header]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sonnet_number = None\n",
    "sonnets = {}\n",
    "in_between_sonnets = True\n",
    "\n",
    "for line in cleaned:\n",
    "    is_empty = len(line) == 0\n",
    "    if in_between_sonnets:\n",
    "        if is_empty:\n",
    "            pass\n",
    "        elif line.isnumeric():\n",
    "            sonnet_number = int(line)\n",
    "            sonnets[sonnet_number] = []\n",
    "        elif sonnet_number is not None:\n",
    "            in_between_sonnets = False\n",
    "            sonnets[sonnet_number].append(line)\n",
    "        else:\n",
    "            # wait for sonnet number\n",
    "            pass\n",
    "    else:\n",
    "        if is_empty:\n",
    "            in_between_sonnets = True\n",
    "            sonnet_number = None\n",
    "        else:\n",
    "            sonnets[sonnet_number].append(line)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def canonicalize(s):\n",
    "    no_punctuation = ''.join([c for c in s if c.isalpha() or c == ' '])\n",
    "    return no_punctuation.lower().strip()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def encode(strs):\n",
    "    # The Bert paper mentions prepending a [CLS] token and adding a [SEP] token to separate sentences\n",
    "    # https://arxiv.org/pdf/1810.04805.pdf\n",
    "    # However, this seems to make the scores worse, so we don't do it\n",
    "    with torch.no_grad():\n",
    "        encoded_input = tokenizer(strs, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "        encoded_input = {k: v.to(device) for k, v in encoded_input.items()}\n",
    "        model_output = model(**encoded_input)\n",
    "    return model_output.last_hidden_state[:, 0, :].detach().cpu().numpy()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.DataFrame([{'sonnet_number': sonnet_number, 'line_number': line_index+1, 'text': text,\n",
    "                    'embeddings': encode([canonicalize(text)])[0]}\n",
    "                   for sonnet_number, lines in sonnets.items()\n",
    "                   for line_index, text in enumerate(lines)])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "embeddings = np.vstack(df.embeddings.values)\n",
    "print(embeddings.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "d = embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(d)\n",
    "index.add(embeddings)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    xq = encode([canonicalize(query)])\n",
    "    D, I = index.search(xq, k=10)\n",
    "    result = df.iloc[I[0]][['sonnet_number', 'line_number', 'text']]\n",
    "    result['distance'] = D[0]\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "search(\"rough winds shake the flowers of spring\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Find the most similar lines\n",
    "search(\"Rough winds do shake the darling buds of May,\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Clustering\n",
    "Let's try to cluster the lines into topics."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n_centroids = 10\n",
    "n_iter = 100\n",
    "verbose = True\n",
    "\n",
    "k_means = faiss.Kmeans(d, n_centroids, niter=n_iter, verbose=verbose)\n",
    "k_means.train(embeddings)\n",
    "assignments = k_means.assign(embeddings)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_clusters = df.copy()\n",
    "df_clusters['cluster'] = assignments[1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_clusters[df_clusters['cluster']==0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n_sonnets = len(set(df_clusters['sonnet_number']))\n",
    "\n",
    "# See docs: https://networkx.org/documentation/stable/auto_examples/drawing/plot_multipartite_graph.html#sphx-glr-auto-examples-drawing-plot-multipartite-graph-py\n",
    "G = nx.Graph()\n",
    "\n",
    "def cluster_node(i):\n",
    "    return f'C{i}'\n",
    "\n",
    "def sonnet_node(sn):\n",
    "    return f'S{sn}'\n",
    "\n",
    "for sn in set(df_clusters.sonnet_number.values):\n",
    "    G.add_node(sonnet_node(sn), layer=1, type='sonnet', label=f'Sonnet {sn}')\n",
    "\n",
    "for c in range(n_centroids):\n",
    "    G.add_node(cluster_node(c), layer=0, type='cluster', label=f'Cluster {c}')\n",
    "\n",
    "for i, r in df_clusters.iterrows():\n",
    "    u = cluster_node(r.cluster)\n",
    "    v = sonnet_node(r.sonnet_number)\n",
    "    G.add_edge(u,v, weight=10) # weight is the attractive force"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pos=nx.spring_layout(G,weight='weight')\n",
    "type_to_col = {'sonnet':'red', 'cluster':'blue'}\n",
    "cols = [type_to_col[d['type']] for n,d in G.nodes(data=True)]\n",
    "nx.draw_networkx(G,pos=pos, node_color=cols,  with_labels=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_clusters[df_clusters['cluster']==0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Graphing by mean embedding"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_means = pd.DataFrame()\n",
    "df_means['sonnet_number'] = df.sonnet_number.unique()\n",
    "df_means['mean_embedding'] = [np.mean(df[df['sonnet_number']==sn]['embeddings'].values)\n",
    "                              for sn in df_means.sonnet_number.values]\n",
    "\n",
    "df_means"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n_sonnets = df_means.shape[0]\n",
    "\n",
    "mean_embeddings = np.vstack(df_means.mean_embedding)\n",
    "mean_embeddings.shape\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_tsne = TSNE(n_components=2).fit_transform(mean_embeddings)\n",
    "\n",
    "plt.scatter(X_tsne[:, 0], X_tsne[:, 1])\n",
    "\n",
    "for i,sn in enumerate(df_means.sonnet_number.values):\n",
    "    plt.annotate(f'S {sn}', (X_tsne[i, 0], X_tsne[i, 1]))\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
