{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import urllib.request\n",
    "import itertools\n",
    "\n",
    "import faiss\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "import matplotlib_inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.manifold import TSNE\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "MODEL_DIR = pathlib.Path().absolute().parent / \"models\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define the device to use, using a CUDA GPU if available.\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the pre-trained tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased', cache_dir=MODEL_DIR)\n",
    "model = AutoModel.from_pretrained('bert-base-uncased').to(device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Download the sonnets (free for non-commercial use)\n",
    "url = \"https://flgr.sh/txtfssSontxt\"\n",
    "document = [b.decode('UTF-8') for b in urllib.request.urlopen(url).readlines()]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "without_header = list(itertools.dropwhile(lambda x: len(x.strip()) > 0, document))\n",
    "cleaned = [str(line).strip() for line in without_header]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sonnet_number = None\n",
    "sonnets = {}\n",
    "in_between_sonnets = True\n",
    "\n",
    "for line in cleaned:\n",
    "    is_empty = len(line) == 0\n",
    "    if in_between_sonnets:\n",
    "        if is_empty:\n",
    "            pass\n",
    "        elif line.isnumeric():\n",
    "            sonnet_number = int(line)\n",
    "            sonnets[sonnet_number] = []\n",
    "        elif sonnet_number is not None:\n",
    "            in_between_sonnets = False\n",
    "            sonnets[sonnet_number].append(line)\n",
    "        else:\n",
    "            # wait for sonnet number\n",
    "            pass\n",
    "    else:\n",
    "        if is_empty:\n",
    "            in_between_sonnets = True\n",
    "            sonnet_number = None\n",
    "        else:\n",
    "            sonnets[sonnet_number].append(line)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sentences = [(f\"Sonnet {sonnet_number}\\r\\n\" + \"\\r\\n\".join(sonnets[sonnet_number])).lower()\n",
    "             for sonnet_number in sorted(sonnets.keys())]\n",
    "print(sentences[17])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def encode(strs):\n",
    "    encoded_input = tokenizer(strs, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    encoded_input = {k: v.to(device) for k, v in encoded_input.items()}\n",
    "    model_output = model(**encoded_input)\n",
    "    return model_output.last_hidden_state[:, 0, :].detach().cpu().numpy()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# encode one at a time to avoid memory issues\n",
    "sentence_embeddings = np.vstack([encode(sentence) for sentence in sentences])\n",
    "sentence_embeddings.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "d = sentence_embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(d)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "index.add(sentence_embeddings)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "k = 3\n",
    "xq = encode([\"profitless usurer why dost thou use so great a sum of sums yet canst not live\"])\n",
    "D, I = index.search(xq, k)\n",
    "print(D, I)\n",
    "for i in I[0]:\n",
    "    print(f\"** SENTENCE={i}:\", sentences[i], \"\\r\\n\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Plot the embedding space\n",
    "The embedding space is 768-dimensional, so we need to reduce it to 2 dimensions to plot it.\n",
    "We can use tSNE for this."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "labels = [\n",
    "    #\"youth\", \"old age\", \"death\", \"decay\", \"time\", \"poetry\", \"arts\", \"children\", \"parenthood\", \"man\", \"woman\", \"anger\", \"jealousy\"\n",
    "    \"time passing, youth, old age, death and decay\",\n",
    "]\n",
    "label_embeddings = encode(labels)\n",
    "\n",
    "all_embeddings = np.vstack([sentence_embeddings, label_embeddings])\n",
    "X_tsne = TSNE(n_components=2).fit_transform(all_embeddings)\n",
    "S_tsne = X_tsne[:len(sentences)]\n",
    "L_tsne = X_tsne[len(sentences):]\n",
    "\n",
    "plt.scatter(S_tsne[:, 0], S_tsne[:, 1])\n",
    "plt.scatter(L_tsne[:, 0], L_tsne[:, 1], c=\"red\")\n",
    "\n",
    "for i, label in enumerate(labels):\n",
    "    plt.annotate(label, (L_tsne[i, 0], L_tsne[i, 1]))\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Compute the nearest neighbors on the raw embeddings\n",
    "nbrs = NearestNeighbors(n_neighbors=10, algorithm='ball_tree').fit(sentence_embeddings)\n",
    "distances, indices = nbrs.kneighbors(sentence_embeddings)\n",
    "\n",
    "print(distances[:3, :3])\n",
    "print(indices[:3, :3])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "for i, sentence in enumerate(sentences):\n",
    "    G.add_node(i, label=sentence[:20])\n",
    "\n",
    "for i in range(len(sentences)):\n",
    "    for j in range(1, nbrs.n_neighbors):\n",
    "        p1, p2 = indices[i][0], indices[i][j]\n",
    "        dist = distances[i][j]\n",
    "        w = dist * dist\n",
    "        G.add_edge(p1, p2, weight=1.0 / w, length=dist)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "plt.subplot(121)\n",
    "pos = nx.spring_layout(G, weight='weight', k=0.1, iterations=50)\n",
    "nx.draw_networkx(G, pos, node_size=10, font_size=10, width=0.1, alpha=0.5, with_labels=True)\n",
    "\n",
    "plt.subplot(122)\n",
    "pos = nx.kamada_kawai_layout(G)\n",
    "nx.draw_networkx(G, pos, node_size=10, font_size=10, width=0.1, alpha=0.5, with_labels=True)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#edge_labels = nx.get_edge_attributes(G, 'weight')\n",
    "#nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(indices[:3, :3])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "G.add_nodes_from(indices[:, 0])\n",
    "for i in indices[:, 0]:\n",
    "    for j in range(1, nbrs.n_neighbors):\n",
    "        u = i\n",
    "        v = indices[i][j]\n",
    "        dist = distances[i][j]\n",
    "        G.add_edge(u, v, dist=dist)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dx = {}\n",
    "for u, v, d in G.edges(data=True):\n",
    "    if dx.get(u) is None:\n",
    "        dx[u] = {}\n",
    "    dx[u][v] = d['dist']\n",
    "\n",
    "pos = nx.kamada_kawai_layout(G, dist=dx)\n",
    "nx.draw_networkx(G, pos, node_size=10, font_size=10, width=0.1, alpha=0.5, with_labels=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
